# 智能系统Lab_2说明文档

###### 18307130251 蒋晓雯

## `HMM`

### 统计

1. 统计训练集中开始字各标签的发射概率Pi
2. 统计训练集中标签转移的概率（标签转移矩阵）A
3. 统计个标签发射语料集中各汉字的发射概率B

### 预测

1. 维特比解码，动态规划，存了一个字典，分别是每次以四个标签结束的最佳分词结果，下一个字进来之后，重新打分，获得新的最佳的四种分词，分别以四个不同标签结束，最终打分最高的分词结果就是预测结果。
2. 生词的处理：
   - 前一个是S：把当前发射S、B的概率置为0.00000001
   - 前一个是B：把当前发射I、E的概率置为0.00000001
   - 前一个是I：把当前发射I、E的概率置为0.00000001
   - 前一个是E：把当前发射S、B的概率置为0.00000001

## `CRF`

由于语料集太大跑起来比较慢，我划了一个比较小的样本来进行试验。训练集27万字左右，开发集3万字左右。开发集和训练集的比例是1 : 9。

另外用来看分词效果的三个测试的句子分别是“我爱北京天安门”、“今天天气怎么样”和“自挂东南枝”。

接下来我们开始实验！

### 不同模板下的对比实验

窗口为3的基础模板

$template_{base}:C_{-1},C_{0},C_{1},C_{-1}C_{0},C_{0}C_{1},C_{-1}C_{1}$

增加了一些其他的特征模板进行对比实验。

| 模板 | epoch | right rate | S(-1)S(1) | C(-2) | C(2) | C(-2)C(-1) | C(-2)C(0) | C(0)C(2) | C(1)C(2) |
| ---- | ----- | ---------- | --------- | ----- | ---- | ---------- | --------- | -------- | -------- |
| 5    | 76    | 91.036%    | √         | ×     | ×    | √          | √         | ×        | ×        |
| 10   | 91    | 91.032%    | √         | ×     | ×    | √          | ×         | ×        | ×        |
| 9    | 85    | 90.991%    | √         | ×     | ×    | √          | √         | √        | √        |
| 1    | 32    | 90.787%    | ×         | ×     | ×    | ×          | ×         | ×        | ×        |
| 3    | 47    | 90.746%    | ×         | ×     | ×    | √          | ×         | ×        | ×        |
| 2    | 61    | 90.706%    | √         | ×     | ×    | ×          | ×         | ×        | ×        |
| 6    | 74    | 90.653%    | √         | √     | ×    | √          | √         | ×        | ×        |
| 8    | 30    | 90.434%    | ×         | √     | √    | √          | √         | √        | √        |
| 7    | 58    | 90.424%    | ×         | √     | ×    | √          | √         | ×        | ×        |
| 4    | 41    | 90.401%    | ×         | ×     | ×    | √          | √         | ×        | ×        |

<center><strong>表 1 - 不同模板下的实验结果（按在开发集上的正确率倒序排）</strong></center>

其实总体来看最终能达到的最高的正确率相差并不大，在千分之五之内，所以这个误差也有可能是由于训练集和开发集的选择原因造成的，这里就不过多讨论。

唯一一个在开发集上正确率超过原始模板$template_1$的只有$template_5$和$template_9$，并且$template_5$和$template_9$的收敛速度明显慢于$template_1$，达到峰值的速度是$template_1$的一倍还要多。

但是可以很明显的看出，不同特征模板使得模型收敛的速度并不相同，收敛快的模板速度将近是慢的的一倍。加了标签转移模板$S_{-1}S_{0}$的模型，普遍收敛速度慢一些。

特征模板的数量和模型收敛的速度也无关，这里看$template_8$，虽然模板数量最多，但是没有转移标签模板$S_{-1}S_{0}$，它的收敛也是最快的

#### 1. $C_{-2}、C_{2}$

一个并不意外的结果是距离当前观察值较远的字$C_{-2}$和$C_{2}$反而会使得正确率下降。由于汉字的组合过于多样化，太远的字反而对分词来说可能是一种噪声。

#### 2.$S_{-1}S_{0}$

标签转移模板$S_{-1}S_{0}$会使得模型的收敛速度减慢，但也提高了一部分分词的正确率。

对于没加转移模板的$template_1$的分词结果是：

```bash
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBBE

句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBEBBE

句子= 自挂东南枝
实际= SSBES
预测= BEBIE
```

加了转移模板的$template_2$的分词结果：

```
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBIE

句子= 今天天气怎么样
实际= BEBEBIE
预测= BESSSBE

句子= 自挂东南枝
实际= SSBES
预测= SBEBE
```

可以看到对“我爱北京天安门”这句句子，$template_1$给出了连续两个B的分词结果，这显然是不合理的，$template_2$就解决了这个问题。

但标签转移模板也会带来其他的问题，对于“自 挂 东南 枝”的分词，$template_1$可以做到分成"自挂 东南枝"，看起来还是合理的，但$template_2$会极其不正确的将其分为"自 挂东 南枝"。“今天天气怎么样”，虽然$template_1$的分词结果有两个异常的连续的B，但$template_2$的分词更加离谱，分成了“今天 天 气 怎 么样”。

根据实验结果，标签转移模板带来的错误影响比它带来的正确影响要大。

#### 3.$C_{-2}C_{-1},C_{-2}C_{0}$

根据上面的实验，离得远的单字$C_{-2}、C_{2}$对于模型的正确率有错误的影响，所以一件很自然的事情就是$C_{-2}C_{-1},C_{-2}C_{0}$也会有错误的影响。

但是把$C_{-2}C_{-1},C_{-2}C_{0}$和$S_{-1}S_{0}$组合使用能够大大提高模型的正确率。可能是因为$S_{-1}S_{0}$对$[-1]$这个位置上的标签进行了管理，所以这两个有转移的特征同时作用反倒会产生很好的效果。

并且仅是把这两个模板组合使用效果最佳，再加上单字等别的模板均会使正确率下降。

$template_5$的分词结果：

```bash
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBIE

句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBIEBE

句子= 自挂东南枝
实际= SSBES
预测= SBEBE
```

$template_5$成功的分对了第一句，但对于后面两句的分词结果还是非常的让人迷惑，和$template_2$的分词结果非常相似。

#### 4.$C_{1}C_{2},C_{0}C_{2}$

根据实验和上述的分析，虽然$template_9$的效果也不错，正确率超过了原始模板，但达不到$template_5$的正确率且收敛速度更慢。可能的原因是没有一个向后的标签转移模板$S_{0}S_{1}$的存在，并且由于相对位置$[2]$的字里当前观察的的字太远了，反而引入了一部分噪声。

### 分词结果分析（各模板的分词结果在最后的附录部分）

我选择的三句句子，第一句是陈述句，第二句是疑问句，第三句是古诗。

对于第一句，正确率较高的$template_5$和$template_9$都可以正确分对。对于最后一句古诗，$template_9$可以分成"自 挂 东南枝"，而我预想的分词结果是“自 挂 东南 枝”，只有细微的偏差，姑且可以看做正确。但是对于第二句疑问句，没有任何一个模型可以把“怎么样”这三个字成功的分成一个词，但是这三个字实际上是非常常用的词，可见`CRF`的建模能力是有一定局限性的。

## `Bi-LSTM-CRF`





## 附录

### 分词测试结果

$template_1$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBBE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBEBBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= BEBIE
```

$template_2$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBIE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BESSSBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= SBEBE
```

$template_3$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBBE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBEBBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= SEBIE
```

$template_4$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBBE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBEBBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= SEBIE
```

$template_5$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBIE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBIEBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= SBEBE
```

$template_6$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBESBE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBESBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= SBEBE
```

$template_7$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SBBEBBE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBEBEE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= SBBIE
```

$template_8$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBBE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBIBBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= BEBEE
```

$template_9$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBIE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBIEBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= SSBIE
```

$template_{10}$

```
[ 0 ]:
句子= 我爱北京天安门
实际= SSBEBIE
预测= SSBEBIE
[ 1 ]:
句子= 今天天气怎么样
实际= BEBEBIE
预测= BEBIEBE
[ 2 ]:
句子= 自挂东南枝
实际= SSBES
预测= SBEBE
```



$template_1$

$template_1$

$template_1$

$template_1$

